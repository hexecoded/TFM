\chapter{Introducción}

En este primer punto, describiremos de forma breve la motivación a realizar este TFM. Analizaremos la importancia de poseer herramientas capaces de realizar una predicción a largo plazo en series temporales (en inglés,\textit{ Long-term Time Series Forecasting},  LSTF), pero, sobre todo, centrándonos en un aspecto clave: la codificación posicional (\textit{Positional Encoding}, en adelante, PE), común a prácticamente todas las alternativas actuales del estado del arte. 

Procederemos a justificar su importancia, así como a formular los objetivos que se cubren con la realización de este trabajo.
\section{Motivación}

En la actualidad, los datos son uno de los bienes más preciados. Las telecomunicaciones nos han permitido alcanzar un volumen inimaginable de información digital, la cual no somos prácticamente capaces de procesar, y extraer conocimiento útil se convierte en una tarea complicada. Su gran variedad y modalidad hace necesario disponer de modelos multimodales cada vez más complejos para procesarlos, como los modelos fundacionales, para tratar así de disponer de una herramienta cercana a ser capaz de procesar todo tipo de información.\\

Hemos podido apreciar grandes avances en el procesamiento de texto, con los grandes modelos de lenguaje como GPT, el cual se ha convertido en una herramienta que usamos habitualmente para resolver nuestras dudas. Ahora, incluso permite generar imágenes, video y audio, y pensar profudamente las respuestas.\\

Sin embargo, estos no son los únicos tipos de datos que podemos emplear para aprender. Los datos basados en flujos, y las series temporales, son un recurso clave que podemos emplear para resolver multitud de problemáticas. Podemos predecir a largo plazo, clasificar fenómenos, o bien, incluso detectar anomalías. En este trabajo, nos centraremos sobre todo en la primera tarea y las dificultades que existen en este ámbito.

\subsection{Importancia de las Series Temporales}

Las series temporales son un tipo de datos en los que la estructura temporal de los mismos es clave. Normalmente, están compuestos por una o varias variables muestreadas a lo largo del tiempo, siguiendo un intervalo de tiempo ordenado entre instancias, y que tratan de recabar información acerca de un fenómeno. Normalmente, estos se suelen registrar de forma periódica, siguiendo un diferencial de tiempo entre instancias fijo, fruto de su muestreo mediante sensores o procesos automatizados. Por ejemplo, la temperatura de un motor de coche recogida por el sensor del termostato. Pero también es posible encontrarla de manera menos regular, cuando, por ejemplo, es muestreada manualmente. Como mencionamos, además, las series temporales pueden contener una o más variables, las cuales idealmente deben ser muestreadas a la misma frecuencia para disponer de un conjunto de datos utilizable de manera sencilla, y evitar así la necesidad de aplicar técnicas de inputación, que pueden alterar los resultados.\\

El objetivo: utilizar estos datos para aprender qué ocurrirá en instantes futuros, realizando predicciones en un horizonte concreto pero desconocido. Sin embargo, es importante destacar que no todos los fenómenos pueden ser predichos aunque dispongamos de un conjunto de datos suficiente y adecuado. Es esencial que, para que la técnica sea efectiva, estemos ante una tarea de forecasting, es decir, de predicción de elementos futuros, pero pudiéndonos apoyar en información pasada para comprender el fenómeno que estamos estudiando. Por ejemplo, tratar de predecir la temperatura que hará en las próximas 2 horas, en intervalos de 15 minutos,es una tarea viable: disponemos de elementos clave como la tendencia de las horas anteriores, y los valores históricos de días previos, o incluso años anteriores en el mismo día del año, que pueden ser útiles.\\

Pero, podríamos abordar casos más complejos, como es el realizado a diario por Red Eléctrica para conocer el consumo estimado de electricidad, y ser capaz de responder con los tipos de energía adecuados, de manera que no sobre en exceso, pero el sistema no quede corto. Se apoyan en los datos históricos de consumo, pero también es necesario tener en cuenta la información recibida de sensores y mediciones de diferentes estaciones eléctricas para tratar de evitar fluctuaciones y problemas de sincronización. Y a esto, se suman otros posibles factores externos, como la climatología, o los problemas de la red provenientes de otros países a los que exista interconexión.
Tras la experiencia vivida en abril de 2025, queda en evidencia la importancia de esta tarea, ya que en caso de error, las consecuencias pueden ser muy graves: personas atrapadas en ascensores, hospitales en emergencia, problemas de tráfico, interrupción de la cadena de frío en los alimentos...
Las pérdidas económicas se consideraron oscilar entre 1.600 y 2.500 millones de euros.

Por tanto, disponer de buenas técnicas de estudio para series temporales es una herramienta clave en multitud de aplicaciones. Manualmente, podemos realizar aproximaciones posibles para casos sencillos, donde apreciamos un comportamiento repetitivo en el tiempo de la serie (estacionalidad) o un comportamiento estrictamente creciente o decreciente linealmente (tendencia). Pero, cuando el problema adquiere un poco de complejidad, o tenemos múltiples variables, usar matemática simple o el sentido común es insuficiente, y son necesarias nuevas técnicas que permitan realizar este proceso de manera, al menos, aproximada, pero fiel al posible comportamiento real.\\

Es ahí donde podemos encontrar herramientas y procedimientos ampliamente conocidos, como la descomposición de series en diferentes componentes: tendencia, estacionalidad y ruido. Una de las técnicas más usadas es ARIMA (AutoRegressive Integrated Moving Average). Se basa en utilizar una ventana deslizable sobre la que ir calculando una media móvil, es decir, un intervalo de amplitud \textit{q} entorno a un valor central, el cual se va moviendo de izquierda a derecha para evaluar con todas las instancias de la serie, y en una componente autoregresiva, que trata de incorporar información de instantes anteriores al que se esta evaluando (hasta p valores). También se integra la serie tantas veces como sea necesario para suavizar su comportamiento. De esta forma, conseguimos obtener una predicción adecuada siempre que el problema se adapte a ciertas condiciones (que estudiaremos más adelante).\\

Sin embargo, en toda esta problemática existe un valor clave: el tamaño del horizonte de predicción. Si queremos resolver predicciones a largo plazo, técnicas como ARIMA verán incrementada su error de manera creciente, debido a que tendrá que apoyarse sobre sus propios valores predichos para obtener valores demasiado alejados de los datos conocidos, acumulando progresivamente el error. 

Es necesario, por tanto, la existencia de nuevas técnicas más avanzadas que nos permitan reducir el error en la medida de lo posible.
\subsection{La dificultad de predicción a largo plazo: información posicional}
\section{Justificación}


\section{Objetivos}

\section{Planificación}